{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/27a_sul@lab.graphicon.ru/miniconda3/envs/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ai-forever/rugpt2large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 1280)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '<|pad|>', 'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>'})\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size=256):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=block_size\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 18oCseBD3UpD2ode0TQqMHlcLMULNa1cZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/27a_sul@lab.graphicon.ru/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_path = \"aneki.txt\"\n",
    "train_dataset = load_dataset(file_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1353' max='1353' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1353/1353 44:27, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.064100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.917600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.825900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.577200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.573600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.577700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.573700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1353, training_loss=2.8445280177982664, metrics={'train_runtime': 2670.7288, 'train_samples_per_second': 16.232, 'train_steps_per_second': 0.507, 'total_flos': 4.71054907342848e+16, 'train_loss': 2.8445280177982664, 'epoch': 2.9958483254912815})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model_output\",       # –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–æ–¥–µ–ª—å\n",
    "    overwrite_output_dir=True,        # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
    "    num_train_epochs=3,               # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "    per_device_train_batch_size=4,    # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–µ–π\n",
    "    gradient_accumulation_steps=8,    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞\n",
    "    save_steps=500,                   # –ö–∞–∫ —á–∞—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã\n",
    "    save_total_limit=2,               # –ú–∞–∫—Å–∏–º—É–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤\n",
    "    logging_dir=\"./logs\",             # –õ–æ–≥–∏\n",
    "    logging_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    fp16=True,                        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Å–º–µ—à–∞–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å\n",
    "    prediction_loss_only=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_rugpt2/tokenizer_config.json',\n",
       " './fine_tuned_rugpt2/special_tokens_map.json',\n",
       " './fine_tuned_rugpt2/vocab.json',\n",
       " './fine_tuned_rugpt2/merges.txt',\n",
       " './fine_tuned_rugpt2/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./fine_tuned_rugpt2\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_rugpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = GPT2LMHeadModel.from_pretrained(\"./fine_tuned_rugpt2\")\n",
    "\n",
    "fine_tuned_tokenizer = GPT2Tokenizer.from_pretrained(\"./fine_tuned_rugpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "<|startoftext|>–í –æ–¥–Ω–æ–º –∏–∑ –∫–∞—Ñ–µ.- –ú–∞–¥–∞–º, —ç—Ç–æ –∂–µ –≤—ã –≤—á–µ—Ä–∞ –ø—Ä–æ–¥–∞–ª–∏ –º–Ω–µ —Ç–æ—Ä—Ç \"–ù–∞–ø–æ–ª–µ–æ–Ω\"?- –î–∞, –∞ —á—Ç–æ?- –ê –ø–æ—á–µ–º—É —É –≤–∞—Å —Ç–æ–≥–¥–∞ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ä–µ–±–µ–Ω–∫–∞?!\n",
      "\n",
      "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É –∫–∏–Ω–æ–∑–≤–µ–∑–¥—ã, –ø–æ—á–µ–º—É –æ–Ω–∞ –¥–æ —Å–∏—Ö –ø–æ—Ä –Ω–µ –∑–∞–º—É–∂–µ–º.- –ü–æ–Ω–∏–º–∞–µ—Ç–µ, —è –Ω–µ —Ö–æ—á—É –≤—ã—Ö–æ–¥–∏—Ç—å –∑–∞–º—É–∂, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ä—Ç–∏—Ç—å —Å–≤–æ–π –≥–∞—Ä–¥–µ—Ä–æ–±.\n",
      "\n",
      "- –ö–∞–∫ —Ç—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª—Å—è —Å –º–æ–µ–π –∂–µ–Ω–æ–π?- –Ø –ø—Ä–æ—Ö–æ–¥–∏–ª –º–∏–º–æ –∏ —É–≤–∏–¥–µ–ª, –∫–∞–∫ –æ–Ω–∞ –∏–¥–µ—Ç –ø–æ —É–ª–∏—Ü–µ, –Ω—É —è –∏ —Ä–µ—à–∏–ª –ø–æ–¥–æ–π—Ç–∏ –∏ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è\n",
      "\n",
      "########################################################################################################################\n",
      "\n",
      "Sample 2:\n",
      "<|startoftext|>–û–± —ç—Ç–æ–º —É–∂–µ –∑–Ω–∞—é—Ç –≤—Å–µ, –∫—Ä–æ–º–µ —Ç–µ—Ö, –∫—Ç–æ –Ω–∞ —ç—Ç–æ –ø–æ–¥–ø–∏—Å–∞–ª—Å—è.\n",
      "\n",
      "- –î–∞ –≤—ã –ø—Ä–æ—Å—Ç–æ –ø@—Ä–Ω—É—Ö–∞ –∫–∞–∫–æ–π-—Ç–æ! - –∑–∞—è–≤–∏–ª–∞ —Å–æ—Å–µ–¥–∫–∞ –º–æ–µ–π –∂–µ–Ω–µ –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ —è –∫—É–ø–∏–ª —É –Ω–µ–µ –ø—ã–ª–µ—Å–æ—Å.- –î–∞, –∫–æ–Ω–µ—á–Ω–æ, –Ω–æ –∑–∞—Ç–æ –≤ —Ö–æ—Ä–æ—à–µ–º –∫–∞—á–µ—Å—Ç–≤–µ!\n",
      "\n",
      "–ö–∞–∫ –∏–∑–≤–µ—Å—Ç–Ω–æ, —Å–∞–º—ã–µ –ª—É—á—à–∏–µ –¥—Ä—É–∑—å—è - —ç—Ç–æ –≤—Ä–∞–≥–∏.–ù–æ –±—ã–≤–∞–µ—Ç —Ç–∞–∫, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –¥—Ä—É–∑—å—è –º–æ–≥—É—Ç —Å—Ç–∞—Ç—å —Å–∞–º—ã–º–∏ –∑–ª–µ–π—à–∏–º–∏ –≤—Ä–∞–≥–∞–º–∏.\n",
      "\n",
      "–ü—Ä–∏—Ö–æ–¥–∏—Ç –º—É–∂ –¥–æ–º–æ–π, –∂–µ–Ω–∞ —Å —Ä–∞–±–æ—Ç—ã -\n",
      "\n",
      "########################################################################################################################\n",
      "\n",
      "Sample 3:\n",
      "<|startoftext|>- –ü–∞–ø–∞, –∞ –æ—Ç–∫—É–¥–∞ –±–µ—Ä—É—Ç—Å—è –¥–µ—Ç–∏?- –ê —è —Ç–µ–±–µ –±–æ–ª—å—à–µ —Å–∫–∞–∂—É, —Å—ã–Ω–æ–∫, –∏–∑ –∑–∞–¥–Ω–∏—Ü—ã!\n",
      "\n",
      "–ù–∞ —ç–∫–∑–∞–º–µ–Ω–µ –≤ –º–µ–¥–∏–Ω—Å—Ç–∏—Ç—É—Ç–µ:- –ù–∞–∑–æ–≤–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –≤—ã –æ—Ç–ª–∏—á–∞–µ—Ç–µ –º—É–∂—Å–∫—É—é –≥–æ–ª–æ–≤—É –æ—Ç –∂–µ–Ω—Å–∫–æ–π?- –ù—É, –≤–æ-–ø–µ—Ä–≤—ã—Ö, –æ–Ω–∏ –¥–ª–∏–Ω–Ω–µ–µ.\n",
      "\n",
      "–ü–æ –¥–∞–Ω–Ω—ã–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, 80% –ª—é–¥–µ–π, –ø–æ—Ç–µ—Ä—è–≤—à–∏—Ö –¥–µ–Ω—å–≥–∏ –Ω–∞ —É–ª–∏—Ü–µ, –Ω–µ –º–æ–≥—É—Ç –≤—Å–ø–æ–º–Ω–∏—Ç—å –≥–¥–µ —ç—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ.\n",
      "\n",
      "- –ö–∞–∫ –≤—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å?- –Ø —Å–ª—É—á–∞–π–Ω–æ –ø—Ä–æ—Ö–æ–¥–∏–ª –º–∏–º–æ –µ–µ –ø–æ–¥—ä–µ–∑–¥–∞. –£–≤–∏–¥–µ–ª –µ–µ —Å —Å–∏–≥–∞—Ä–µ—Ç–æ–π\n",
      "\n",
      "########################################################################################################################\n",
      "\n",
      "Sample 4:\n",
      "<|startoftext|>–ú—É–∂ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∏–∑ –∫–æ–º–∞–Ω–¥–∏—Ä–æ–≤–∫–∏ –∏ –≥–æ–≤–æ—Ä–∏—Ç –∂–µ–Ω–µ:- –ú–∏–ª–∞—è, –º—ã —Å —Ç–æ–±–æ–π –Ω–µ —Å—Å–æ—Ä–∏–ª–∏—Å—å?\n",
      "\n",
      "–í –¥–µ–Ω—å, –∫–æ–≥–¥–∞ –≤ –†–æ—Å—Å–∏–∏ –ø–µ—Ä–µ—Å—Ç–∞–Ω—É—Ç –≤—ã–ø—É—Å–∫–∞—Ç—å —Å–ø–∏—Ä—Ç–Ω–æ–µ –∏ –Ω–∞ –ø—Ä–∏–ª–∞–≤–∫–∞—Ö –ø–æ—è–≤–∏—Ç—Å—è –≤–æ–¥–∫–∞, –≤ –ö–∏–µ–≤–µ —Å–æ—Å—Ç–æ–∏—Ç—Å—è –ø–∞—Ä–∞–¥ –Ω–∞ –ö—Ä–∞—Å–Ω–æ–π –ø–ª–æ—â–∞–¥–∏.\n",
      "\n",
      "–ù–∞ —É—Ä–æ–∫–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏:- –î–µ—Ç–∏, –∞ —Ç–µ–ø–µ—Ä—å –Ω–∞—Ä–∏—Å—É–π—Ç–µ –≥–æ—Ä–æ–¥ –≤ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–µ!- –Ø –≤ –Ω–µ–≥–æ –Ω–µ –≤–ø–∏—Å—ã–≤–∞—é—Å—å!- –ù–µ –∑–Ω–∞—é, –∫–∞–∫ –≤ —Ç–≤–æ–π –≥–æ—Ä–æ–¥ –≤–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –æ—Å—Ç–∞–ª—å–Ω—ã–µ –¥–µ—Ç–∏, –∞ –≤–æ—Ç —è –≤ –Ω–µ–≥–æ –≤–ø–∏—Å—ã–≤–∞—é—Å—å...\n",
      "\n",
      "–ï—Å–ª–∏ –±—ã –Ω–µ\n",
      "\n",
      "########################################################################################################################\n",
      "\n",
      "Sample 5:\n",
      "<|startoftext|>- –ù—É, –≤–æ—Ç, –µ—â–µ –æ–¥–∏–Ω –º–æ–π –ø—Ä–æ–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–∏–∫–∞–∫ –Ω–µ —Ä–µ–∞–ª–∏–∑—É–µ–º.- –ò —á—Ç–æ –∂–µ —Ç—ã —Ç–∞–º –ø—Ä–∏–¥—É–º–∞–ª?- –û–≥–æ—Ä–æ–¥ –∏ –∫—Ä–æ–ª–∏–∫–æ–≤.\n",
      "\n",
      "- –ß—Ç–æ –æ–±—â–µ–≥–æ –º–µ–∂–¥—É –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º –∏ –∂–µ–Ω—â–∏–Ω–æ–π?- –ò —Ç–æ—Ç –∏ –¥—Ä—É–≥–∞—è —Ä–∞–±–æ—Ç–∞—é—Ç –¥–æ –ø–æ—Ç–µ—Ä–∏ –ø—É–ª—å—Å–∞.\n",
      "\n",
      "–ñ–µ–Ω—â–∏–Ω–∞ –∑–≤–æ–Ω–∏—Ç –Ω–∞ —Ä–∞–±–æ—Ç—É —Å–≤–æ–µ–º—É –ø–∞—Ä–Ω—é:- –û–π, —á—Ç–æ —ç—Ç–æ –∑–∞ –∂—É—Ç–∫–∏–π –≤–æ–π? –¢—ã –≤ –æ–ø–∞—Å–Ω–æ—Å—Ç–∏?- –ù–µ—Ç, –Ω–æ –º–Ω–µ –Ω—É–∂–Ω–æ —Å—Ä–æ—á–Ω–æ —É–ª–∞–¥–∏—Ç—å –æ–¥–Ω–æ –¥–µ–ª–æ, –ø–æ—ç—Ç–æ–º—É –º–µ–Ω—è –¥–æ–ª–≥–æ –Ω–µ –±—É–¥–µ—Ç, –∫ –≤–µ—á–µ—Ä—É –≤–µ—Ä–Ω—É—Å—å.–ñ–µ–Ω–∞, —Ä–∞–¥–æ—Å—Ç–Ω–æ:-\n",
      "\n",
      "########################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=fine_tuned_tokenizer, device=0)\n",
    "\n",
    "num_samples = 5\n",
    "\n",
    "result = generator(\n",
    "    \"<|startoftext|>\",\n",
    "    max_length=100,             # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "    num_return_sequences=5,    # –°–∫–æ–ª—å–∫–æ —Å—ç–º–ø–ª–æ–≤ –Ω—É–∂–Ω–æ\n",
    "    do_sample=True,            # –í–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "    temperature=1.0,           # –†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è\n",
    "    top_k=50,                  # –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ 50 –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤\n",
    "    top_p=0.9                  # Nucleus sampling: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞, —Å—É–º–º–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∫–æ—Ç–æ—Ä—ã—Ö <= 0.9\n",
    ")\n",
    "\n",
    "for i, sample in enumerate(result):\n",
    "    print(f\"\\nSample {i + 1}:\\n{sample['generated_text']}\\n\")\n",
    "    print('#' * 120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
